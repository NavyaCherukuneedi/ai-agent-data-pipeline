
# AI-Agent Driven Data Engineering Pipeline ğŸš€

This is a GitHub-ready starter project using **CrewAI** and **LangGraph** to build a modular data pipeline with AI agents for:
- Data ingestion
- Cleaning
- Validation
- Loading
- Monitoring

## ğŸ§± Tech Stack
- CrewAI (LLM agent framework)
- LangGraph + LangChain
- Airbyte (data ingestion)
- DuckDB (storage)
- Great Expectations (data validation)
- Prefect (orchestration)
- Open-source LLM (Ollama, LLaMA.cpp)

## ğŸ“ Structure
```
.
â”œâ”€â”€ agents/               # LLM agent definitions (CleanerAgent, ValidatorAgent, etc.)
â”œâ”€â”€ data/                 # Raw and processed data
â”œâ”€â”€ pipelines/            # Modular pipeline stages
â”œâ”€â”€ config/               # Agent and tool configurations
â”œâ”€â”€ utils/                # Helper functions
â”œâ”€â”€ orchestration/        # Prefect flows or Airflow DAGs
â”œâ”€â”€ models/               # Trained models or embeddings
â”œâ”€â”€ logs/                 # Logs and artifacts
â””â”€â”€ README.md             # This file
```

## ğŸ§  Example Agent: CleanerAgent
Located in `agents/cleaner_agent.py`, it uses a local LLM via CrewAI to remove nulls and standardize columns.

## ğŸ“¦ Setup
```bash
git clone https://github.com/yourusername/ai_agent_data_pipeline.git
cd ai_agent_data_pipeline
pip install -r requirements.txt
```

## âš™ï¸ Run Pipeline
```bash
python orchestration/run_pipeline.py
```

Enjoy building AI-powered data workflows!
